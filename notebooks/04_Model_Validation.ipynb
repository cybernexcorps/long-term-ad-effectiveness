{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Phase 4: Model Validation and Diagnostics\n\nThis notebook validates the MMM models using:\n1. MCMC Convergence Diagnostics (R-hat, ESS, trace plots)\n2. Posterior Predictive Checks (MAPE, R², coverage)\n3. Model Fit Quality Assessment\n4. Parameter Interpretation\n\n**Prerequisites:** Run notebooks 02 and 03 first to fit the models"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nsys.path.append('..')\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport arviz as az\nfrom scripts.mmm_optimized import UCM_MMM_Optimized\nfrom scripts.bvar_optimized import BVAR_Optimized\n\nprint(\"=\"*70)\nprint(\"NOTE: This notebook assumes you have already run:\")\nprint(\"  1. 02_Short_Term_Model.ipynb (fitted mmm object)\")\nprint(\"  2. 03_Long_Term_Model.ipynb (fitted bvar object)\")\nprint(\"=\"*70)\nprint(\"\\nIf you haven't run those notebooks, run them first!\")\nprint(\"This notebook will demonstrate validation using synthetic results.\")\nprint(\"\\nFor actual validation, you would load the fitted model objects\")\nprint(\"from the previous notebooks using pickle or by re-running them.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC Convergence Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# MCMC Convergence Diagnostics\n\nprint(\"=\"*70)\nprint(\"1. CONVERGENCE DIAGNOSTICS\")\nprint(\"=\"*70)\n\n# Assuming 'mmm' and 'bvar' objects are available from previous notebooks\n# If not, this demonstrates the validation process\n\nprint(\"\\n## UCM-MMM Model Convergence\")\nprint(\"-\" * 70)\n\n# Get summary statistics\n# summary_mmm = mmm.summary()\n\n# Example of what to check:\nprint(\"\"\"\nKey metrics to check:\n\n1. R-hat (Gelman-Rubin statistic):\n   - R-hat < 1.01 = EXCELLENT convergence\n   - R-hat < 1.05 = Good convergence\n   - R-hat > 1.05 = Poor convergence (increase draws)\n   \n   Example check:\n   ```python\n   summary = mmm.summary()\n   rhat_max = summary['r_hat'].max()\n   print(f\"Max R-hat: {rhat_max:.4f}\")\n   \n   if rhat_max < 1.01:\n       print(\"✓ EXCELLENT convergence!\")\n   ```\n\n2. Effective Sample Size (ESS):\n   - ESS > 1000 = Good (for 500 draws × 4 chains = 2000 total)\n   - ESS > 400 = Acceptable\n   - ESS < 400 = Poor (increase draws)\n   \n   Example check:\n   ```python\n   ess_min = summary['ess_bulk'].min()\n   print(f\"Min ESS: {ess_min:.0f}\")\n   \n   if ess_min > 1000:\n       print(\"✓ Sufficient effective samples!\")\n   ```\n\n3. Divergences:\n   - 0 divergences = Ideal\n   - < 1% divergences = Acceptable\n   - > 5% divergences = Problematic\n   \n   Example check:\n   ```python\n   # Access from trace\n   n_divergences = mmm.trace.sample_stats['diverging'].sum().values\n   total_samples = len(mmm.trace.posterior.chain) * len(mmm.trace.posterior.draw)\n   pct_divergent = n_divergences / total_samples * 100\n   \n   print(f\"Divergences: {n_divergences} ({pct_divergent:.2f}%)\")\n   ```\n\"\"\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Predictive Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Posterior Predictive Checks\n\nprint(\"=\"*70)\nprint(\"2. POSTERIOR PREDICTIVE CHECKS\")\nprint(\"=\"*70)\n\nprint(\"\"\"\nPosterior predictive checks validate model fit by comparing:\n- Actual observed sales\n- Model-predicted sales (from posterior)\n\nKey metrics:\n\n1. MAPE (Mean Absolute Percentage Error):\n   - MAPE < 10% = Excellent fit\n   - MAPE < 20% = Good fit\n   - MAPE > 20% = Poor fit (model may need refinement)\n\n2. R² (Coefficient of Determination):\n   - R² > 0.9 = Excellent fit\n   - R² > 0.7 = Good fit\n   - R² < 0.5 = Poor fit\n\n3. 95% CI Coverage:\n   - Should be ~95% (actual sales within credible interval)\n   - < 90% = Model underestimates uncertainty\n   - > 98% = Model overestimates uncertainty\n\nExample implementation:\n\"\"\")\n\nprint(\"\"\"\n```python\nimport arviz as az\n\n# Generate posterior predictive samples\nwith mmm.model:\n    ppc = az.sample_posterior_predictive(\n        mmm.trace,\n        var_names=['y_obs'],\n        random_seed=42\n    )\n\n# Extract predictions\ny_pred = ppc.posterior_predictive['y_obs'].values\ny_pred_mean = y_pred.mean(axis=(0, 1))\ny_pred_lower = np.percentile(y_pred, 2.5, axis=(0, 1))\ny_pred_upper = np.percentile(y_pred, 97.5, axis=(0, 1))\n\n# Calculate metrics\nactual_sales = df['revenue'].values\nresiduals = actual_sales - y_pred_mean\n\n# MAPE\nmape = np.mean(np.abs(residuals / actual_sales)) * 100\nprint(f\"MAPE: {mape:.2f}%\")\n\n# R²\nr2 = 1 - np.sum(residuals**2) / np.sum((actual_sales - actual_sales.mean())**2)\nprint(f\"R²: {r2:.3f}\")\n\n# Coverage\ncoverage = np.mean((actual_sales >= y_pred_lower) & (actual_sales <= y_pred_upper)) * 100\nprint(f\"95% CI Coverage: {coverage:.1f}%\")\n```\n\"\"\")\n\n# Visualization example\nprint(\"\\nVisualization:\")\nprint(\"\"\"\n```python\nfig, ax = plt.subplots(figsize=(14, 6))\n\n# Plot actual sales\nax.plot(df['Date'], actual_sales, 'o-', color='black', \n        linewidth=2, markersize=3, label='Actual Sales', alpha=0.7)\n\n# Plot predicted mean\nax.plot(df['Date'], y_pred_mean, '-', color='#2E86AB', \n        linewidth=2, label='Predicted Mean')\n\n# Plot credible interval\nax.fill_between(df['Date'], y_pred_lower, y_pred_upper,\n                 color='#2E86AB', alpha=0.2, label='95% CI')\n\nax.set_xlabel('Date', fontsize=12, fontweight='bold')\nax.set_ylabel('Sales Revenue ($)', fontsize=12, fontweight='bold')\nax.set_title('Posterior Predictive Check: Model Fit Quality', \n             fontsize=14, fontweight='bold', pad=20)\nax.legend(loc='upper left')\nax.grid(True, alpha=0.3)\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n```\n\"\"\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Parameter Interpretation\n\nprint(\"=\"*70)\nprint(\"3. PARAMETER INTERPRETATION\")\nprint(\"=\"*70)\n\nprint(\"\"\"\nUnderstanding model parameters helps validate business logic:\n\n## UCM-MMM Parameters\n\n1. **Adstock (α)**: Carryover rate\n   ```python\n   alpha = mmm.trace.posterior['alpha'].mean(dim=['chain', 'draw']).values\n   \n   for i, channel in enumerate(marketing_channels):\n       print(f\"{channel}: α = {alpha[i]:.3f}\")\n       \n   # Interpretation:\n   # α = 0.3 → Effects decay quickly (30% remains next week)\n   # α = 0.5 → Moderate persistence (half-life of ~1 week)\n   # α = 0.7 → Strong carryover (half-life of ~2 weeks)\n   ```\n\n2. **Saturation (λ, κ)**: Diminishing returns\n   ```python\n   lambda_vals = mmm.trace.posterior['lambda'].mean(dim=['chain', 'draw']).values\n   kappa_vals = mmm.trace.posterior['kappa'].mean(dim=['chain', 'draw']).values\n   \n   for i, channel in enumerate(marketing_channels):\n       print(f\"{channel}:\")\n       print(f\"  λ (half-saturation): ${lambda_vals[i]:,.0f}\")\n       print(f\"  κ (shape): {kappa_vals[i]:.2f}\")\n       \n   # Interpretation:\n   # λ = Half-saturation point (spend where effectiveness drops 50%)\n   # κ > 1 → S-shaped curve (slow start, rapid growth, plateau)\n   # κ < 1 → Rapid initial returns, then diminishing\n   ```\n\n3. **Channel Effects (β)**: Direct impact\n   ```python\n   # After hierarchical effects\n   beta = mmm.trace.posterior['beta_channel'].mean(dim=['chain', 'draw']).values\n   \n   for i, channel in enumerate(marketing_channels):\n       print(f\"{channel}: β = {beta[i]:.4f}\")\n       \n   # Interpretation:\n   # Higher β = stronger direct effect on sales\n   # Can compare relative strength across channels\n   ```\n\n## BVAR Parameters\n\n1. **VAR Coefficients (A)**: Lag effects\n   ```python\n   A_lag1 = bvar.trace.posterior['A_lag1'].mean(dim=['chain', 'draw']).values\n   \n   # Shows how each variable affects itself and others\n   # Large positive values = strong persistence\n   # Negative values = mean reversion\n   ```\n\n2. **Exogenous Effects (B)**: Marketing impact\n   ```python\n   B = bvar.trace.posterior['B'].mean(dim=['chain', 'draw']).values\n   \n   # B[i, j] = effect of marketing channel j on outcome i\n   # Positive values = marketing increases brand/sales\n   ```\n\n## Validation Checklist:\n\n✓ Parameters have reasonable magnitude\n✓ Sign (positive/negative) makes business sense  \n✓ Credible intervals don't include extreme values\n✓ Hierarchical effects show expected grouping\n✓ Adstock/saturation curves look plausible\n\"\"\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}